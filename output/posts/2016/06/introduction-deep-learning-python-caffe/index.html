<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Adil Moujahid, Bridging Tech and Art">


        
<style type="text/css">
pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
</style>

<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
div.entry-content {
  overflow: visible;
  padding: 8px;
}
.input_area {
  padding: 0.2em;
}

a.heading-anchor {
 white-space: normal;
}

.rendered_html
code {
 font-size: .8em;
}

pre.ipynb {
  color: black;
  background: #f7f7f7;
  border: none;
  box-shadow: none;
  margin-bottom: 0;
  padding: 0;
  margin: 0px;
  font-size: 13px;
}

/* remove the prompt div from text cells */
div.text_cell .prompt {
    display: none;
}

/* remove horizontal padding from text cells, */
/* so it aligns with outer body text */
div.text_cell_render {
    padding: 0.5em 0em;
}

img.anim_icon{padding:0; border:0; vertical-align:middle; -webkit-box-shadow:none; -box-shadow:none}

div.collapseheader {
    width=100%;
    background-color:#d3d3d3;
    padding: 2px;
    cursor: pointer;
    font-family:"Helvetica Neue",Helvetica,Arial,sans-serif;
}
</style>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: true,
        displayMath: [['$$','$$'], ["\\[","\\]"]]
    }
});
</script>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>

<script type="text/javascript">
jQuery(document).ready(function($) {
    $("div.collapseheader").click(function () {
    $header = $(this).children("span").first();
    $codearea = $(this).children(".input_area");
    console.log($(this).children());
    $codearea.slideToggle(500, function () {
        $header.text(function () {
            return $codearea.is(":visible") ? "Collapse Code" : "Expand Code";
        });
    });
});
});
</script>




        <title>A Practical Introduction to Deep Learning with Caffe and Python // Adil Moujahid // Bridging Tech and Art</title>



    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.3.0/pure-min.css">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.1.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="../../../../theme/css/bootstrap.min.css">
    <link rel="stylesheet" href="../../../../theme/css/pure.css">
    <link rel="stylesheet" href="../../../../theme/css/pygments.css">
    <link rel="stylesheet" href="../../../../theme/css/custom.css">


    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

    <script src="//load.sumome.com/" data-sumo-site-id="4ce3990f4d6fb482b4d97fa9208bd2242f7bb8c711ce30290794390dbe7ed180" async></script>

    <link rel="shortcut icon" type="image/x-icon" href="../../../../extra/favicon.ico" />

</head>

<body>
<div class="pure-g-r" id="layout">
    <div class="sidebar sidebar-article pure-u">
        <header class="header-article">
            <hgroup>
                <a href="../../../../author/adil-moujahid.html" title="See posts by Adil Moujahid">
                        <img class="avatar" alt="Adil Moujahid" src="http://www.gravatar.com/avatar/2ac2a00f5911cc8234778be41c835e13">
                </a>
                <h2 class="article-info">Adil Moujahid</h2>
                <small class="about-author"></small>

                <!-- ko-fi -->
                <div>
                    <a href='https://ko-fi.com/W7W4K1LZ' target='_blank'><img height='36' src='https://az743702.vo.msecnd.net/cdn/kofi4.png?v=0' style='border:0px;height:32px;' border='0' alt='Buy Me a Coffee at ko-fi.com' /></a>
                </div>
                <br>

                <div>
                <a href="https://twitter.com/AdilMouja" class="twitter-follow-button" data-show-count="false">
                    Follow @AdilMouja
                </a>
                <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
                </div>

                <h5>Published</h5>
                <p>Sun 26 June 2016</p>
                <a href="/">&larr;Home</a>
            </hgroup>
        </header>
    </div>
    <div class="pure-u">
        <div class="content">
            <section class="post">
                <header class="post-header">
                    <h1>A Practical Introduction to Deep Learning with Caffe and Python</h1>
                    <br>
                    <p class="post-meta">
                        // tags                             <a class="post-category" href="../../../../tag/deep-learning/">deep learning</a>
                            <a class="post-category" href="../../../../tag/machine-learning/">machine learning</a>
                            <a class="post-category" href="../../../../tag/python/">python</a>
                            <a class="post-category" href="../../../../tag/caffe/">caffe</a>
                    </p>
                </header>
            </section>
            <br>
            <p>Deep learning is the new big trend in machine learning. It had many recent successes in computer vision, automatic speech recognition and natural language processing.</p>
<p>The goal of this blog post is to give you a hands-on introduction to deep learning. To do this, we will build a Cat/Dog image classifier using a deep learning algorithm called convolutional neural network (CNN) and a <a href="https://www.kaggle.com/c/dogs-vs-cats">Kaggle dataset</a>.</p>
<p>This post is divided into 2 main parts. The first part covers some core concepts behind deep learning, while the second part is structured in a hands-on tutorial format.</p>
<p>In the first part of the hands-on tutorial (section 4), we will build a Cat/Dog image classifier using a convolutional neural network from scratch. In the second part of the tutorial (section 5), we will cover an advanced technique for training convolutional neural networks called transfer learning. We will use some Python code and a popular open source deep learning framework called Caffe to build the classifier. Our classifier will be able to achieve a classification accuracy of 97%.</p>
<p>By the end of this post, you will understand how convolutional neural networks work, and you will get familiar with the steps and the code for building these networks.</p>
<p>The source code for this tutorial can be found in this <a href="https://github.com/adilmoujahid/deeplearning-cats-dogs-tutorial">github repository</a>.</p>
<h1>1. Problem Definition</h1>
<p>In this tutorial, we will be using a dataset from <a href="https://www.kaggle.com/c/dogs-vs-cats">Kaggle</a>. The dataset is comprised of 25,000 images of dogs and cats. </p>
<p>Our goal is to build a machine learning algorithm capable of detecting the correct animal (cat or dog) in new unseen images. </p>
<p>In Machine learning, this type of problems is called classification. </p>
<div style="text-align:center">
<p><img alt="Alt Text" src="/images/cats-dogs.jpg"></p>
</div>
<h1>2. Classification using Traditional Machine Learning vs. Deep Learning</h1>
<p>Classification using a machine learning algorithm has 2 phases:</p>
<ul>
<li>Training phase: In this phase, we train a machine learning algorithm using a dataset comprised of the images and their corresponding labels.</li>
<li>Prediction phase: In this phase, we utilize the trained model to predict labels of unseen images.</li>
</ul>
<p>The training phase for an image classification problem has 2 main steps:</p>
<ol>
<li>
<p>Feature Extraction: In this phase, we utilize domain knowledge to extract new features that will be used by the machine learning algorithm. <a href="https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients">HoG</a> and <a href="https://en.wikipedia.org/wiki/Scale-invariant_feature_transform">SIFT</a> are examples of features used in image classification.</p>
</li>
<li>
<p>Model Training: In this phase, we utilize a clean dataset composed of the images' features and the corresponding labels to train the machine learning model.</p>
</li>
</ol>
<p>In the predicition phase, we apply the same feature extraction process to the new images and we pass the features to the trained machine learning algorithm to predict the label.</p>
<div style="text-align:center">
<p><img alt="Alt Text" src="/images/machine-learning-training-prediction-2.png"></p>
</div>
<p>The main difference between traditional machine learning and deep learning algorithms is in the feature engineering. In traditional machine learning algorithms, we need to hand-craft the features. By contrast, in deep learning algorithms feature engineering is done automatically by the algorithm. 
Feature engineering is difficult, time-consuming and requires domain expertise. The promise of deep learning is more accurate machine learning algorithms compared to traditional machine learning with less or no feature engineering.</p>
<div style="text-align:center">
<p><img alt="Alt Text" src="/images/traditional-ml-deep-learning-2.png"></p>
</div>
<h1>3. A Crash Course in Deep Learning</h1>
<p>Deep learning refers to a class of artificial neural networks (ANNs) composed of many processing layers. ANNs existed for many decades, but attempts at training deep architectures of ANNs failed until Geoffrey Hinton's breakthrough work of the mid-2000s. In addition to algorithmic innovations, the increase in computing capabilities using GPUs and the collection of larger datasets are all factors that helped in the recent surge of deep learning.</p>
<h2>3.1. Artificial Neural Networks (ANNs)</h2>
<p>Artificial neural networks (ANNs) are a family of machine learning models inspired by biological neural networks. </p>
<h3>Artificial Neural Networks vs. Biological Neural Networks</h3>
<p>Biological Neurons are the core components of the human brain. A neuron consists of a cell body, dendrites, and an axon. It processes and transmit information to other neurons by emitting electrical signals. Each neuron receives input signals from its dendrites and produces output signals along its axon. The axon branches out and connects via synapses to dendrites of other neurons. </p>
<p>A basic model for how the neurons work goes as follows: Each synapse has a strength that is learnable and control the strength of influence of one neuron on another. The dendrites carry the signals to the target neuron's body where they get summed. If the final sum is above a certain threshold, the neuron get fired, sending a spike along its axon.[1]</p>
<p>Artificial neurons are inspired by biological neurons, and try to formulate the model explained above in a computational form. An artificial neuron has a finite number of inputs with weights associated to them, and an activation function (also called transfer function). The output of the neuron is the result of the activation function applied to the weighted sum of inputs. Artificial neurons are connected with each others to form artificial neural networks.</p>
<div style="text-align:center">
<p><img alt="Alt Text" src="/images/neurons.png"></p>
</div>
<h3>Feedforward Neural Networks</h3>
<p>Feedforward Neural Networks are the simplest form of Artificial Neural Networks. </p>
<p>These networks have 3 types of layers: Input layer, hidden layer and output layer. In these networks, data moves from the input layer through the hidden nodes (if any) and to the output nodes. </p>
<p>Below is an example of a fully-connected feedforward neural network with 2 hidden layers. "Fully-connected" means that each node is connected to all the nodes in the next layer. </p>
<p>Note that, the number of hidden layers and their size are the only free parameters. The larger and deeper the hidden layers, the more complex patterns we can model in theory.</p>
<div style="text-align:center">
<p><img alt="Alt Text" src="/images/feedforward-nn.png"></p>
</div>
<h3>Activation Functions</h3>
<p>Activation functions transform the weighted sum of inputs that goes into the artificial neurons. These functions should be non-linear to encode complex patterns of the data. The most popular activation functions are Sigmoid, Tanh and ReLU. ReLU is the most popular activation function in deep neural networks.</p>
<div style="text-align:center">
<p><img alt="Alt Text" src="/images/activation.png"></p>
</div>
<h3>Training Artificial Neural Networks</h3>
<p>The goal of the training phase is to learn the network's weights.  We need 2 elements to train an artificial neural network:</p>
<ul>
<li>Training data: In the case of image classification, the training data is composed of images and the corresponding labels.</li>
<li>Loss function: A function that measures the inaccuracy of predictions. </li>
</ul>
<p>Once we have the 2 elements above, we train the ANN using an algorithm called backpropagation together with gradient descent (or one of its derivatives). For a detailed explanation of backpropagation, I recommend this <a href="https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/">article</a>. </p>
<h2>3.2. Convolutional Neural Networks (CNNs or ConvNets)</h2>
<p>Convolutional neural networks are a special type of feed-forward networks. These models are designed to emulate the behaviour of a visual cortex. CNNs perform very well on visual recognition tasks. 
CNNs have special layers called convolutional layers and pooling layers that allow the network to encode certain images properties. </p>
<div style="text-align:center">
<p><img alt="Alt Text" src="/images/lenet.png"></p>
</div>
<h2>Convolution Layer</h2>
<p>This layer consists of a set of learnable filters that we slide over the image spatially, computing dot products between the entries of the filter and the input image. The filters should extend to the full depth of the input image. For example, if we want to apply a filter of size 5x5 to a colored image of size 32x32, then the filter should have depth 3 (5x5x3) to cover all 3 color channels (Red, Green, Blue) of the image. These filters will activate when they see same specific structure in the images. </p>
<div style="text-align:center">
<p><img alt="Alt Text" src="/images/conv-layer.png"></p>
</div>
<h2>Pooling Layer</h2>
<p>Pooling is a form of non-linear down-sampling. The goal of the pooling layer is to progressively reduce the spatial size of the representation to reduce the amount of parameters and computation in the network, and hence to also control overfitting. There are several functions to implement pooling among which max pooling is the most common one. Pooling is often applied with filters of size 2x2 applied with a stride of 2 at every depth slice. A pooling layer of size 2x2 with stride of 2 shrinks the input image to a 1/4 of its original size. [2]</p>
<div style="text-align:center">
<p><img alt="Alt Text" src="/images/max-pooling.png"></p>
</div>
<h2>Convolutional Neural Networks Architecture</h2>
<p>The simplest architecture of a convolutional neural networks starts with an input layer (images) followed by a sequence of convolutional layers and pooling layers, and ends with fully-connected layers. The convolutional layers are usually followed by one layer of ReLU activation functions. </p>
<p>The convolutional, pooling and ReLU layers act as learnable features extractors, while the fully connected layers acts as a machine learning classifier. Furthermore, the early layers of the network encode generic patterns of the images, while later layers encode the details patterns of the images.</p>
<p>Note that only the convolutional layers and fully-connected layers have weights. These weights are learned in the training phase. </p>
<div style="text-align:center">
<p><img alt="Alt Text" src="/images/cnn-architecture.png"></p>
</div>
<h1>4. Building a Cat/Dog Classifier using a Convolutional Neural Network</h1>
<p>In this section, we will implement a cat/dog classifier using a convolutional neural network. We will use a dataset from Kaggle's <a href="https://www.kaggle.com/c/dogs-vs-cats">Dogs vs. Cats competition</a>. To implement the convolutional neural network, we will use a deep learning framework called Caffe and some Python code.</p>
<h2>4.1 Getting Dogs &amp; Cats Data</h2>
<p>First, we need to download 2 datasets from the <a href="https://www.kaggle.com/c/dogs-vs-cats/data">competition page</a>: train.zip and test1.zip. The train.zip file contains labeled cats and dogs images that we will use to train the network. The test1.zip file contains unlabeled images that we will classify to either dog or cat using the trained model. We will upload our predictions to Kaggle to get the score of our prediction model.</p>
<h2>4.2 Machine Setup</h2>
<p>To train convolutional neural networks, we need a machine with a powerful GPU. </p>
<p>In this tutorial, I used one <a href="https://aws.amazon.com/">AWS</a> EC2 instance of type g2.2xlarge. This instance has a high-performance NVIDIA GPU with 1,536 CUDA cores and 4GB of video memory, 15GB of RAM and 8 vCPUs. The machine costs $0.65/hour.</p>
<p>If you're not familiar with AWS, this <a href="http://cs231n.github.io/aws-tutorial/">guide</a> will help you set up an AWS EC2 instance. </p>
<p>Please note, that the AMI recommended in the guide is no longer available. I prepared a new AMI (ami-64d31209) with all the necessary software installed. I also created a <a href="https://github.com/adilmoujahid/deeplearning-cats-dogs-tutorial/blob/master/aws-ec2-setup.md">guide</a> for installing Caffe and Anaconda on an AWS EC2 instance or an Ubuntu machine with GPU.</p>
<p>After setting up an AWS instance, we connect to it and clone the github repository that contains the necessary Python code and Caffe configuration files for the tutorial. From your terminal, execute the following command.</p>
<div class="highlight"><pre><span></span><code>git clone https://github.com/adilmoujahid/deeplearning-cats-dogs-tutorial.git
</code></pre></div>

<p>Next, we create an <code>input</code> folder for storing the training and test images.</p>
<div class="highlight"><pre><span></span><code>cd deeplearning-cats-dogs-tutorial
mkdir input
</code></pre></div>

<h2>4.3 Caffe Overview</h2>
<p>Caffe is a deep learning framework developed by the Berkeley Vision and Learning Center (<a href="http://bvlc.eecs.berkeley.edu/">BVLC</a>). It is written in C++ and has Python and Matlab bindings. </p>
<p>There are 4 steps in training a CNN using Caffe:</p>
<ul>
<li>Step 1 - Data preparation: In this step, we clean the images and store them in a format that can be used by Caffe. We will write a Python script that will handle both image pre-processing and storage.</li>
<li>Step 2 - Model definition: In this step, we choose a CNN architecture and we define its parameters in a configuration file with extension <code>.prototxt</code>.</li>
<li>Step 3 - Solver definition:  The solver is responsible for model optimization. We define the solver parameters in a configuration file with extension <code>.prototxt</code>. </li>
<li>Step 4 - Model training: We train the model by executing one Caffe command from the terminal. After training the model, we will get the trained model in a file with extension <code>.caffemodel</code>.</li>
</ul>
<p>After the training phase, we will use the <code>.caffemodel</code> trained model to make predictions of new unseen data. We will write a Python script to this.</p>
<h2>4.4 Data Preparation</h2>
<p>We start by copying the train.zip and test1.zip (that we downloaded to our local machine) to the <code>input</code> folder in the AWS instance. We can do this using the <code>scp</code> command from a MAC or linux machine. If you're running Windows, you can use a program such as <a href="https://winscp.net/eng/download.php">Winscp</a>. After copying the data, we unzip the files by executing the following commands:</p>
<div class="highlight"><pre><span></span><code>unzip ~/deeplearning-cats-dogs-tutorial/input/train.zip
unzip ~/deeplearning-cats-dogs-tutorial/input/test1.zip
rm ~/deeplearning-cats-dogs-tutorial/input/*.zip
</code></pre></div>

<p>Next, we run <code>create_lmdb.py</code>.</p>
<div class="highlight"><pre><span></span><code>cd ~/deeplearning-cats-dogs-tutorial/code
python create_lmdb.py
</code></pre></div>

<p><code>create_lmdb.py</code> script does the following:</p>
<ul>
<li>Run histogram equalization on all training images. Histogram equalization is a technique for adjusting the contrast of images. </li>
<li>Resize all training images to a 227x227 format.</li>
<li>Divide the training data into 2 sets: One for training (5/6 of images) and the other for validation (1/6 of images). The training set is used to train the model, and the validation set is used to calculate the accuracy of the model. </li>
<li>Store the training and validation in 2 LMDB databases. train_lmdb for training the model and validation_lmbd for model evaluation. </li>
</ul>
<p>Below is the explanation of the most important parts of the code.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">transform_img</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">img_width</span><span class="o">=</span><span class="n">IMAGE_WIDTH</span><span class="p">,</span> <span class="n">img_height</span><span class="o">=</span><span class="n">IMAGE_HEIGHT</span><span class="p">):</span>

    <span class="c1">#Histogram Equalization</span>
    <span class="n">img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">equalizeHist</span><span class="p">(</span><span class="n">img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">equalizeHist</span><span class="p">(</span><span class="n">img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">equalizeHist</span><span class="p">(</span><span class="n">img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">2</span><span class="p">])</span>

    <span class="c1">#Image Resizing</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="n">img_width</span><span class="p">,</span> <span class="n">img_height</span><span class="p">),</span> <span class="n">interpolation</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">INTER_CUBIC</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">img</span>
</code></pre></div>

<p><code>transform_img</code> takes a colored images as input, does the histogram equalization of the 3 color channels and resize the image.</p>
<div style="text-align:center">
<p><img alt="Alt Text" src="/images/image-transform.jpg"></p>
</div>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">make_datum</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>

    <span class="k">return</span> <span class="n">caffe_pb2</span><span class="o">.</span><span class="n">Datum</span><span class="p">(</span>
        <span class="n">channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">width</span><span class="o">=</span><span class="n">IMAGE_WIDTH</span><span class="p">,</span>
        <span class="n">height</span><span class="o">=</span><span class="n">IMAGE_HEIGHT</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span>
        <span class="n">data</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">rollaxis</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">tostring</span><span class="p">())</span>
</code></pre></div>

<p><code>make_datum</code> takes an image and its label and return a <a href="https://github.com/BVLC/caffe/wiki/The-Datum-Object">Datum object</a> that contains the image and its label. </p>
<div class="highlight"><pre><span></span><code><span class="n">in_db</span> <span class="o">=</span> <span class="n">lmdb</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">train_lmdb</span><span class="p">,</span> <span class="n">map_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e12</span><span class="p">))</span>
<span class="k">with</span> <span class="n">in_db</span><span class="o">.</span><span class="n">begin</span><span class="p">(</span><span class="n">write</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">in_txn</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">in_idx</span><span class="p">,</span> <span class="n">img_path</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_data</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">in_idx</span> <span class="o">%</span>  <span class="mi">6</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">img_path</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">IMREAD_COLOR</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">transform_img</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">img_width</span><span class="o">=</span><span class="n">IMAGE_WIDTH</span><span class="p">,</span> <span class="n">img_height</span><span class="o">=</span><span class="n">IMAGE_HEIGHT</span><span class="p">)</span>
        <span class="k">if</span> <span class="s1">&#39;cat&#39;</span> <span class="ow">in</span> <span class="n">img_path</span><span class="p">:</span>
            <span class="n">label</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">label</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">datum</span> <span class="o">=</span> <span class="n">make_datum</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="n">in_txn</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:0&gt;5d}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">in_idx</span><span class="p">),</span> <span class="n">datum</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>
        <span class="nb">print</span> <span class="s1">&#39;</span><span class="si">{:0&gt;5d}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">in_idx</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;:&#39;</span> <span class="o">+</span> <span class="n">img_path</span>
<span class="n">in_db</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div>

<p>The code above takes 5/6 of the training images, transforms and stores them in train_lmdb. The code for storing validation data follows the same structure.</p>
<h3>Generating the mean image of training data</h3>
<p>We execute the command below to generate the mean image of training data. We will substract the mean image from each input image to ensure every feature pixel has zero mean. This is a common preprocessing step in supervised machine learning.</p>
<div class="highlight"><pre><span></span><code><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ubuntu</span><span class="o">/</span><span class="n">caffe</span><span class="o">/</span><span class="n">build</span><span class="o">/</span><span class="n">tools</span><span class="o">/</span><span class="n">compute_image_mean</span><span class="w"> </span><span class="o">-</span><span class="n">backend</span><span class="o">=</span><span class="n">lmdb</span><span class="w"> </span><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ubuntu</span><span class="o">/</span><span class="n">deeplearning</span><span class="o">-</span><span class="n">cats</span><span class="o">-</span><span class="n">dogs</span><span class="o">-</span><span class="n">tutorial</span><span class="o">/</span><span class="n">input</span><span class="o">/</span><span class="n">train_lmdb</span><span class="w"> </span><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ubuntu</span><span class="o">/</span><span class="n">deeplearning</span><span class="o">-</span><span class="n">cats</span><span class="o">-</span><span class="n">dogs</span><span class="o">-</span><span class="n">tutorial</span><span class="o">/</span><span class="n">input</span><span class="o">/</span><span class="n">mean</span><span class="o">.</span><span class="n">binaryproto</span>
</code></pre></div>

<h2>4.4 Model Definition</h2>
<p>After deciding on the CNN architecture, we need to define its parameters in a <code>.prototxt</code> train_val file. Caffe comes with a few popular CNN <a href="https://github.com/BVLC/caffe/tree/master/models">models</a> such as Alexnet and GoogleNet. In this tutorial, we will use the <a href="https://github.com/BVLC/caffe/tree/master/models/bvlc_reference_caffenet">bvlc_reference_caffenet</a> model which is a replication of AlexNet with a few modifications. Below is a copy of the train_val file that we call <code>caffenet_train_val_1.prototxt</code>. If you clone the tutorial git repository as explained above, you should have the same file under <code>deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_1/</code>.</p>
<p>We need to make the modifications below to the original bvlc_reference_caffenet prototxt file:</p>
<ul>
<li>Change the path for input data and mean image: Lines 24, 40 and 51.</li>
<li>Change the number of outputs from 1000 to 2: Line 373. The original bvlc_reference_caffenet was designed for a classification problem with 1000 classes. </li>
</ul>
<div class="gist">
    <script src='https://gist.github.com/3f71cf43ad04c2f04b9af45841e4fed3.js?file=caffenet_train_val_1.prototxt'></script>
    <noscript>
        <pre><code>name: "CaffeNet"
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/ubuntu/cats-dogs-tutorial/input/mean.binaryproto"
  }
# mean pixel / channel-wise mean instead of mean image
#  transform_param {
#    crop_size: 227
#    mean_value: 104
#    mean_value: 117
#    mean_value: 123
#    mirror: true
#  }
  data_param {
    source: "/home/ubuntu/cats-dogs-tutorial/input/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/ubuntu/cats-dogs-tutorial/input/mean.binaryproto"
  }
# mean pixel / channel-wise mean instead of mean image
#  transform_param {
#    crop_size: 227
#    mean_value: 104
#    mean_value: 117
#    mean_value: 123
#    mirror: true
#  }
  data_param {
    source: "/home/ubuntu/cats-dogs-tutorial/input/validation_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}</code></pre>
    </noscript>
</div>
<p>We can print the model architecture by executing the command below. The model architecture image will be stored under <code>deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_1/caffe_model_1.png</code></p>
<div class="highlight"><pre><span></span><code><span class="n">python</span> <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ubuntu</span><span class="o">/</span><span class="n">caffe</span><span class="o">/</span><span class="n">python</span><span class="o">/</span><span class="n">draw_net</span><span class="o">.</span><span class="n">py</span> <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ubuntu</span><span class="o">/</span><span class="n">deeplearning</span><span class="o">-</span><span class="n">cats</span><span class="o">-</span><span class="n">dogs</span><span class="o">-</span><span class="n">tutorial</span><span class="o">/</span><span class="n">caffe_models</span><span class="o">/</span><span class="n">caffe_model_1</span><span class="o">/</span><span class="n">caffenet_train_val_1</span><span class="o">.</span><span class="n">prototxt</span> <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ubuntu</span><span class="o">/</span><span class="n">deeplearning</span><span class="o">-</span><span class="n">cats</span><span class="o">-</span><span class="n">dogs</span><span class="o">-</span><span class="n">tutorial</span><span class="o">/</span><span class="n">caffe_models</span><span class="o">/</span><span class="n">caffe_model_1</span><span class="o">/</span><span class="n">caffe_model_1</span><span class="o">.</span><span class="n">png</span>
</code></pre></div>

<div style="text-align:center">
<p><img alt="Alt Text" src="/images/caffe_model_1.png"></p>
</div>
<h2>4.5 Solver Definition</h2>
<p>The solver is responsible for model optimization. We define the solver's parameters in a <code>.prototxt</code> file. You can find our solver under <code>deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_1/</code> with name <code>solver_1.prototxt</code>. Below is a copy of the same.</p>
<p>This solver computes the accuracy of the model using the validation set every 1000 iterations. The optimization process will run for a maximum of 40000 iterations and will take a snapshot of the trained model every 5000 iterations.</p>
<p><code>base_lr</code>, <code>lr_policy</code>, <code>gamma</code>, <code>momentum</code> and <code>weight_decay</code> are hyperparameters that we need to tune to get a good convergence of the model.</p>
<p>I chose <code>lr_policy: "step"</code> with <code>stepsize: 2500</code>, <code>base_lr: 0.001</code> and <code>gamma: 0.1</code>. In this configuration, we will start with a learning rate of 0.001, and we will drop the learning rate by a factor of ten every 2500 iterations.</p>
<p>There are different strategies for the optimization process. For a detailed explanation, I recommend Caffe's <a href="http://caffe.berkeleyvision.org/tutorial/solver.html">solver documentation</a>.</p>
<div class="gist">
    <script src='https://gist.github.com/3f71cf43ad04c2f04b9af45841e4fed3.js?file=solver_1.prototxt'></script>
    <noscript>
        <pre><code>net: "/home/ubuntu/cats-dogs-tutorial/caffe_models/caffe_model_1/caffenet_train_val_1.prototxt"
test_iter: 1000
test_interval: 1000
base_lr: 0.001
lr_policy: "step"
gamma: 0.1
stepsize: 2500
display: 50
max_iter: 40000
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "/home/ubuntu/cats-dogs-tutorial/caffe_models/caffe_model_1/caffe_model_1"
solver_mode: GPU</code></pre>
    </noscript>
</div>
<h2>4.6 Model Training</h2>
<p>After defining the model and the solver, we can start training the model by executing the command below: </p>
<div class="highlight"><pre><span></span><code><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ubuntu</span><span class="o">/</span><span class="n">caffe</span><span class="o">/</span><span class="n">build</span><span class="o">/</span><span class="n">tools</span><span class="o">/</span><span class="n">caffe</span><span class="w"> </span><span class="n">train</span><span class="w"> </span><span class="o">--</span><span class="n">solver</span><span class="w"> </span><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ubuntu</span><span class="o">/</span><span class="n">deeplearning</span><span class="o">-</span><span class="n">cats</span><span class="o">-</span><span class="n">dogs</span><span class="o">-</span><span class="n">tutorial</span><span class="o">/</span><span class="n">caffe_models</span><span class="o">/</span><span class="n">caffe_model_1</span><span class="o">/</span><span class="n">solver_1</span><span class="o">.</span><span class="n">prototxt</span><span class="w"> </span><span class="mi">2</span><span class="o">&gt;&amp;</span><span class="mi">1</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">tee</span><span class="w"> </span><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ubuntu</span><span class="o">/</span><span class="n">deeplearning</span><span class="o">-</span><span class="n">cats</span><span class="o">-</span><span class="n">dogs</span><span class="o">-</span><span class="n">tutorial</span><span class="o">/</span><span class="n">caffe_models</span><span class="o">/</span><span class="n">caffe_model_1</span><span class="o">/</span><span class="n">model_1_train</span><span class="o">.</span><span class="n">log</span>
</code></pre></div>

<p>The training logs will be stored under <code>deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_1/model_1_train.log</code>.</p>
<p>During the training process, we need to monitor the loss and the model accuracy. We can stop the process at anytime by pressing Ctrl+c. Caffe will take a snapshot of the trained model every 5000 iterations, and store them under <code>caffe_model_1</code> folder.</p>
<p>The snapshots have <code>.caffemodel</code> extension. For example, 10000 iterations snapshot will be called: <code>caffe_model_1_iter_10000.caffemodel</code>.</p>
<h3>Plotting the learning curve</h3>
<p>A learning curve is a plot of the training and test losses as a function of the number of iterations. These plots are very useful to visualize the train/validation losses and validation accuracy. </p>
<p>We can see from the learning curve that the model achieved a validation accuracy of 90%, and it stopped improving after 3000 iterations. </p>
<div class="highlight"><pre><span></span><code>python /home/ubuntu/deeplearning-cats-dogs-tutorial/caffe_models/code/plot_learning_curve.py /home/ubuntu/deeplearning-cats-dogs-tutorial/caffe_models/caffe_models/caffe_model_1/model_1_train.log /home/ubuntu/deeplearning-cats-dogs-tutorial/caffe_models/caffe_models/caffe_model_1/caffe_model_1_learning_curve.png
</code></pre></div>

<div style="text-align:center">
<p><img alt="Alt Text" src="/images/caffe_model_1_learning_curve.png"></p>
</div>
<h2>4.7 Prediction on New Data</h2>
<p>Now that we have a trained model, we can use it to make predictions on new unseen data (images from test1). The Python code for making the predictions is <code>make_predictions_1.py</code> and it's stored under <code>deeplearning-cats-dogs-tutorial/code</code>. The code needs 4 files to run:</p>
<ul>
<li>Test images: We will use test1 images.</li>
<li>Mean image: The mean image that we computed in section 4.4.</li>
<li>Model architecture file: We'll call this file <code>caffenet_deploy_1.prototxt</code>. It's stored under <code>deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_1</code>. It's structured in a similar way to <code>caffenet_train_val_1.prototxt</code>, but with a few modifications. We need to delete the data layers, add an input layer and change the last layer type from SoftmaxWithLoss to Softmax.</li>
<li>Trained model weights: This is the file that we computed in the training phase. We will use <code>caffe_model_1_iter_10000.caffemodel</code>.</li>
</ul>
<p>To run the Python code, we need to execute the command below. The predictions will be stored under <code>deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_1/submission_model_1.csv</code>.</p>
<div class="highlight"><pre><span></span><code>cd /home/ubuntu/deeplearning-cats-dogs-tutorial/code
python make_predictions_1.py
</code></pre></div>

<p>Below is the explanation of the most important parts in the code.</p>
<div class="highlight"><pre><span></span><code><span class="c1">#Read mean image</span>
<span class="n">mean_blob</span> <span class="o">=</span> <span class="n">caffe_pb2</span><span class="o">.</span><span class="n">BlobProto</span><span class="p">()</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;/home/ubuntu/deeplearning-cats-dogs-tutorial/input/mean.binaryproto&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">mean_blob</span><span class="o">.</span><span class="n">ParseFromString</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
<span class="n">mean_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">mean_blob</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
    <span class="p">(</span><span class="n">mean_blob</span><span class="o">.</span><span class="n">channels</span><span class="p">,</span> <span class="n">mean_blob</span><span class="o">.</span><span class="n">height</span><span class="p">,</span> <span class="n">mean_blob</span><span class="o">.</span><span class="n">width</span><span class="p">))</span>


<span class="c1">#Read model architecture and trained model&#39;s weights</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">caffe</span><span class="o">.</span><span class="n">Net</span><span class="p">(</span><span class="s1">&#39;/home/ubuntu/deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_1/caffenet_deploy_1.prototxt&#39;</span><span class="p">,</span>
                <span class="s1">&#39;/home/ubuntu/deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_1/caffe_model_1_iter_10000.caffemodel&#39;</span><span class="p">,</span>
                <span class="n">caffe</span><span class="o">.</span><span class="n">TEST</span><span class="p">)</span>

<span class="c1">#Define image transformers</span>
<span class="n">transformer</span> <span class="o">=</span> <span class="n">caffe</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">Transformer</span><span class="p">({</span><span class="s1">&#39;data&#39;</span><span class="p">:</span> <span class="n">net</span><span class="o">.</span><span class="n">blobs</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">})</span>
<span class="n">transformer</span><span class="o">.</span><span class="n">set_mean</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">mean_array</span><span class="p">)</span>
<span class="n">transformer</span><span class="o">.</span><span class="n">set_transpose</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
</code></pre></div>

<p>The code above stores the mean image under <code>mean_array</code>, defines a model called <code>net</code> by reading the deploy file and the trained model, and defines the transformations that we need to apply to the test images.</p>
<div class="highlight"><pre><span></span><code><span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">img_path</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">IMREAD_COLOR</span><span class="p">)</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">transform_img</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">img_width</span><span class="o">=</span><span class="n">IMAGE_WIDTH</span><span class="p">,</span> <span class="n">img_height</span><span class="o">=</span><span class="n">IMAGE_HEIGHT</span><span class="p">)</span>

<span class="n">net</span><span class="o">.</span><span class="n">blobs</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">forward</span><span class="p">()</span>
<span class="n">pred_probas</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="s1">&#39;prob&#39;</span><span class="p">]</span>
<span class="nb">print</span> <span class="n">pred_probas</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>
</code></pre></div>

<p>The code above read an image, apply similar image processing steps to training phase, calculates each class' probability and prints the class with the largest probability (0 for cats, and 1 for dogs). </p>
<p>After submitting the predicitions to <a href="https://www.kaggle.com/c/dogs-vs-cats/submissions/attach">Kaggle</a>, it give an accuracy of 0.89691.</p>
<div style="text-align:center">
<p><img alt="Alt Text" src="/images/kaggle-1.png"></p>
</div>
<h1>5. Building a Cat/Dog Classifier using Transfer Learning</h1>
<p>In this section, we will use a very practical and powerful technique called transfer learning for building our cat/dog classifier.</p>
<h2>5.1 What is Transfer Learning?</h2>
<p>Convolutional neural networks require large datasets and a lot of computional time to train. Some networks could take up to 2-3 weeks across multiple GPUs to train. Transfer learning is a very useful technique that tries to address both problems. Instead of training the network from scratch, transfer learning utilizes a trained model on a different dataset, and adapts it to the problem that we're trying to solve. </p>
<p>There are 2 strategies for transfer learning:</p>
<ul>
<li>Utilize the trained model as a fixed feature extractor: In this strategy, we remove the last fully connected layer from the trained model, we freeze the weights of the remaining layers, and we train a machine learning classifier on the output of the remaining layers. </li>
<li>Fine-tune the trained model: In this strategy, we fine tune the trained model on the new dataset by continuing the backpropagation. We can either fine-tune the whole network or freeze some of its layers.</li>
</ul>
<p>For a detailed explanation of transfer learning, I recommend reading these <a href="http://cs231n.github.io/transfer-learning/">notes</a>.</p>
<h2>5.2 Training the Cat/Dog Classifier using Transfer Learning</h2>
<p>Caffe comes with a repository that is used by researchers and machine learning practitioners to share their trained models. This library is called <a href="https://github.com/BVLC/caffe/wiki/Model-Zoo">Model Zoo</a>.</p>
<p>We will utilize the trained <a href="https://github.com/BVLC/caffe/tree/master/models/bvlc_reference_caffenet">bvlc_reference_caffenet</a> as a starting point of building our cat/dog classifier using transfer learning. This model was trained on the <a href="http://www.image-net.org/">ImageNet dataset</a> which contains millions of images across 1000 categories.</p>
<p>We will use the fine-tuning strategy for training our model. </p>
<h3>Download trained bvlc_reference_caffenet model</h3>
<p>We can download the trained model by executing the command below.</p>
<div class="highlight"><pre><span></span><code>cd /home/ubuntu/caffe/models/bvlc_reference_caffenet
wget http://dl.caffe.berkeleyvision.org/bvlc_reference_caffenet.caffemodel
</code></pre></div>

<h3>Model Definition</h3>
<p>The model and solver configuration files are stored under <code>deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_2</code>.
We need to make the following change to the original bvlc_reference_caffenet model configuration file.</p>
<ul>
<li>Change the path for input data and mean image: Lines 24, 40 and 51.</li>
<li>Change the name of the last fully connected layer from fc8 to fc8-cats-dogs. Lines 360, 363, 387 and 397.</li>
<li>Change the number of outputs from 1000 to 2: Line 373. The original bvlc_reference_caffenet was designed for a classification problem with 1000 classes. </li>
</ul>
<p>Note that if we keep a layer's name unchanged and we pass the trained model's weights to Caffe, it will pick its weights from the trained model. If we want to freeze a layer, we need to setup its <code>lr_mult</code> parameter to 0.</p>
<div class="gist">
    <script src='https://gist.github.com/42696a9e64a08d7c1b1883d830857d48.js?file=caffenet_train_val_2.prototxt'></script>
    <noscript>
        <pre><code>name: "CaffeNet"
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/ubuntu/cats-dogs-tutorial/input/mean.binaryproto"
  }
# mean pixel / channel-wise mean instead of mean image
#  transform_param {
#    crop_size: 227
#    mean_value: 104
#    mean_value: 117
#    mean_value: 123
#    mirror: true
#  }
  data_param {
    source: "/home/ubuntu/cats-dogs-tutorial/input/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/ubuntu/cats-dogs-tutorial/input/mean.binaryproto"
  }
# mean pixel / channel-wise mean instead of mean image
#  transform_param {
#    crop_size: 227
#    mean_value: 104
#    mean_value: 117
#    mean_value: 123
#    mirror: true
#  }
  data_param {
    source: "/home/ubuntu/cats-dogs-tutorial/input/validation_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-cats-dogs"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8-cats-dogs"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8-cats-dogs"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8-cats-dogs"
  bottom: "label"
  top: "loss"
}</code></pre>
    </noscript>
</div>
<h3>Solver Definition</h3>
<p>We will use a similar solver to the one used in section 4.5.</p>
<div class="gist">
    <script src='https://gist.github.com/42696a9e64a08d7c1b1883d830857d48.js?file=solver_2.prototxt'></script>
    <noscript>
        <pre><code>net: "/home/ubuntu/cats-dogs-tutorial/caffe_models/caffe_model_2/caffenet_train_val_2.prototxt"
test_iter: 1000
test_interval: 1000
base_lr: 0.001
lr_policy: "step"
gamma: 0.1
stepsize: 2500
display: 50
max_iter: 40000
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "/home/ubuntu/cats-dogs-tutorial/caffe_models/caffe_model_2/caffe_model_2"
solver_mode: GPU</code></pre>
    </noscript>
</div>
<h3>Model Training with Transfer Learning</h3>
<p>After defining the model and the solver, we can start training the model by executing the command below. Note that we can pass the trained model's weights by using the argument <code>--weights</code>.</p>
<div class="highlight"><pre><span></span><code><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ubuntu</span><span class="o">/</span><span class="n">caffe</span><span class="o">/</span><span class="n">build</span><span class="o">/</span><span class="n">tools</span><span class="o">/</span><span class="n">caffe</span><span class="w"> </span><span class="n">train</span><span class="w"> </span><span class="o">--</span><span class="n">solver</span><span class="o">=/</span><span class="n">home</span><span class="o">/</span><span class="n">ubuntu</span><span class="o">/</span><span class="n">deeplearning</span><span class="o">-</span><span class="n">cats</span><span class="o">-</span><span class="n">dogs</span><span class="o">-</span><span class="n">tutorial</span><span class="o">/</span><span class="n">caffe_models</span><span class="o">/</span><span class="n">caffe_model_2</span><span class="o">/</span><span class="n">solver_2</span><span class="o">.</span><span class="n">prototxt</span><span class="w"> </span><span class="o">--</span><span class="n">weights</span><span class="w"> </span><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ubuntu</span><span class="o">/</span><span class="n">caffe</span><span class="o">/</span><span class="n">models</span><span class="o">/</span><span class="n">bvlc_reference_caffenet</span><span class="o">/</span><span class="n">bvlc_reference_caffenet</span><span class="o">.</span><span class="n">caffemodel</span><span class="w"> </span><span class="mi">2</span><span class="o">&gt;&amp;</span><span class="mi">1</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">tee</span><span class="w"> </span><span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">ubuntu</span><span class="o">/</span><span class="n">deeplearning</span><span class="o">-</span><span class="n">cats</span><span class="o">-</span><span class="n">dogs</span><span class="o">-</span><span class="n">tutorial</span><span class="o">/</span><span class="n">caffe_models</span><span class="o">/</span><span class="n">caffe_model_2</span><span class="o">/</span><span class="n">model_2_train</span><span class="o">.</span><span class="n">log</span>
</code></pre></div>

<h3>Plotting the Learning Curve</h3>
<p>Similarly to the previous section, we can plot the learning curve by executing the command below. We can see from the learning curve that the model achieved an accuracy of ~97% after 1000 iterations only. This shows the power of transfer learning. We were able to get a higher accuracy with a smaller number of iterations.</p>
<div class="highlight"><pre><span></span><code>python /home/ubuntu/deeplearning-cats-dogs-tutorial/code/plot_learning_curve.py /home/ubuntu/deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_2/model_2_train.log /home/ubuntu/deeplearning-cats-dogs-tutorial/caffe_models/caffe_model_2/caffe_model_2_learning_curve.png
</code></pre></div>

<div style="text-align:center">
<p><img alt="Alt Text" src="/images/caffe_model_2_learning_curve.png"></p>
</div>
<h3>Prediction on New Data</h3>
<p>Similary to section 4.7, we will generate predictions on the test data and upload the results to Kaggle to get the model accuracy. The code for making the predicitions is under <code>deeplearning-cats-dogs-tutorial/code/make_predictions_2.py</code>. </p>
<p>The model got an accuracy of 0.97154 which is better than the model that we trained from scratch. </p>
<div style="text-align:center">
<p><img alt="Alt Text" src="/images/kaggle-2.png"></p>
</div>
<h1>Conclusion</h1>
<p>In this blog post, we covered core concepts of deep learning and convolutional neural networks. We also learned how to build convolutional neural networks using Caffe and Python from scratch and using transfer learning. If you want to learn more about this topic, I highly recommend Stanford's <a href="http://cs231n.github.io/">"Convolutional Neural Networks for Visual Recognition" course</a>. </p>
<h1>References</h1>
<ol>
<li><a href="http://cs231n.github.io/neural-networks-1/">CS231n - Neural Networks Part 1: Setting up the Architecture</a></li>
<li><a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Wikipedia - Convolutional Neural Network</a></li>
<li><a href="http://cs231n.github.io/transfer-learning/">CS231n - Transfer Learning Notes</a></li>
<li><a href="https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/">A Step by Step Backpropagation Example</a></li>
<li><a href="http://cs231n.github.io/">CS231n Convolutional Neural Networks for Visual Recognition</a></li>
</ol>
            <div class="hr"></div>
            
            <!-- Begin MailChimp Signup Form -->
            <link href="//cdn-images.mailchimp.com/embedcode/slim-081711.css" rel="stylesheet" type="text/css">
            <style type="text/css">
                #mc_embed_signup{background:#F1F3F3; clear:left; font:14px Helvetica,Arial,sans-serif; }
                #mc-embedded-subscribe.button{background-color: #0f52ba;}
                /* Add your own MailChimp form style overrides in your site stylesheet or in this style block.
                   We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
            </style>
            <div id="mc_embed_signup">
            <form action="//adilmoujahid.us10.list-manage.com/subscribe/post?u=28846a375fbf5c13a93712283&amp;id=a45c6ff723" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
                <div id="mc_embed_signup_scroll">
                <label for="mce-EMAIL">Subscribe to my Data in Practice Newsletter</label>
                <input type="email" value="" name="EMAIL" class="email" id="mce-EMAIL" placeholder="email address" required>
                <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
                <div style="position: absolute; left: -5000px;"><input type="text" name="b_28846a375fbf5c13a93712283_a45c6ff723" tabindex="-1" value=""></div>
                <div class="clear"><input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
                </div>
            </form>
            </div>

            <!--End mc_embed_signup-->
            <a href="#" class="go-top">Go Top</a>
<div class="comments">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = "adilmoujahid"; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div><footer class="footer">
    <p>&copy; Adil Moujahid &ndash;
        Built with <a href="https://github.com/PurePelicanTheme/pure">Pure Theme</a>
        for <a href="http://blog.getpelican.com/">Pelican</a>
    </p>
</footer>        </div>
    </div>
</div>
    <script>
        var $top = $('.go-top');

        // Show or hide the sticky footer button
        $(window).scroll(function() {
            if ($(this).scrollTop() > 200) {
                $top.fadeIn(200);
            } else {
                $top.fadeOut(200);
            }
        });

        // Animate the scroll to top
        $top.click(function(event) {
            event.preventDefault();
            $('html, body').animate({scrollTop: 0}, 300);
        })

        // Makes sure that the href="#" attached to the <a> elements
        // don't scroll you back up the page.
        $('body').on('click', 'a[href="#"]', function(event) {
            event.preventDefault();
        });

        //Added on 2023-04-12 to fix the CSS of jupyter notebook (padding issue)
        document.addEventListener("DOMContentLoaded", function () {
            const inputPrompt = document.querySelector('.jp-InputPrompt.jp-InputArea-prompt');
            
            if (inputPrompt.textContent.trim() === '') {
                inputPrompt.classList.add('empty');
            } else {
                inputPrompt.classList.remove('empty');
            }
        });


    </script>
    <script type="text/javascript">
        var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
        document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
    </script>
    <script type="text/javascript">
        try {
            var pageTracker = _gat._getTracker("UA-52651211-1");
            pageTracker._trackPageview();
            } catch(err) {}
    </script>
</body>


</html>